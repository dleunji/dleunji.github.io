---
Title : "Ghostwriter Kant API"
layout : post
date : 2021-04-23
category : Internship
blog : true
author : dleunji
description : API ì •ë³µ
---

Teachable-NLPëŠ” ì½”ë“œë¥¼ ë”°ë¡œ ì‘ì„±í•  í•„ìš”ì—†ì´ **í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ íŒŒì¼**ë§Œìœ¼ë¡œ GPT-2ì„ íŠœë‹í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. ë˜í•œ íŠœë‹ëœ ëª¨ë¸ì€ ì„œë²„ì— ìë™ ì—…ë¡œë“œë˜ì–´, APIë¡œ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ í•´ë‹¹ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸€ì„ ìƒì„±í•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê·¸ ì¤‘ ì €ëŠ” ì² í•™ê³¼ í•™ë¶€ ì‹œì ˆ ì¹¸íŠ¸ê°€ ëŒ€ì‹  ê¸€ì„ ì¨ì£¼ì—ˆìœ¼ë©´ ì¢‹ê² ë‹¤ê³  ìì£¼ ìƒìƒí•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìƒìƒì„ ì‹¤í˜„í•˜ê³ ì Teachable NLPì— ì¹¸íŠ¸ì˜ 'ìˆœìˆ˜ì´ì„±ë¹„íŒ'ì„ ì „ì²˜ë¦¬í•˜ì—¬ ë°ì´í„°ë¥¼ í•™ìŠµì‹œì¼°ê³ , ì¹¸íŠ¸ì²˜ëŸ¼ ê¸€ì„ ì“¸ ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ì „ì— [ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •](https://dleunji.github.io/blog/internship/Ghostwriter-Kant-Data/)ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ì˜€ê¸°ì—, ì´ë²ˆì—ëŠ” ëª¨ë¸ì˜ APIë¥¼ í™œìš©í•˜ì—¬ ì„œë¹„ìŠ¤ë¥¼ ì œì‘í•œ ê³¼ì •ì„ ì„¤ëª…í•˜ê³ ì í•©ë‹ˆë‹¤.

1. **ëª¨ë¸ ID í™•ì¸**

ì „ì²˜ë¦¬í•œ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ê³ , TeachableNLPì„ í†µí•œ íŠ¸ë ˆì´ë‹ì´ ëë‚˜ë©´ ì•„ë˜ì™€ ê°™ì€ í™”ë©´ì„ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![_2021-04-16__6 21 07](https://user-images.githubusercontent.com/46207836/115831494-9e958180-a44c-11eb-9135-f5764188f7e2.png)

ì´ ë•Œ, ì£¼ì†Œë¡œ í•´ë‹¹ ëª¨ë¸ì˜ IDë¥¼ ì•Œì•„ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, GPT-2ì— ì¹¸íŠ¸ì˜ 'ìˆœìˆ˜ì´ì„±ë¹„íŒ'ì„ í•™ìŠµì‹œí‚¨ í›„ ì£¼ì†Œì°½ì„ í´ë¦­í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

<img width="621" alt="_2021-04-19__10 21 36" src="https://user-images.githubusercontent.com/46207836/115834651-6b54f180-a450-11eb-8dcc-3262a69f4385.png">

ì´ ë•Œ, ì£¼ì†Œì˜ ë§ë¯¸ì— ìˆëŠ” 4fcddobl91jcdlqrouqhê°€ ëª¨ë¸ì˜ IDì´ê³ , IDë¥¼ í†µí•´ ëª¨ë¸ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

**2. ëª¨ë¸ API**

ëª¨ë¸ì´ ìƒì„±ëœ í™”ë©´ ìš°ì¸¡ì— ìœ„ì¹˜í•œ `View API` ë¥¼ ëˆ„ë¥´ë©´ ëª¨ë¸ì„ í™œìš©í•˜ëŠ” ë°©ë²•ì´ ì•ˆë‚´ë˜ì–´ìˆê³ , `ëª¨ë¸ì˜ ì£¼ì†Œ`ì™€ `API`ë¥¼ íŒŒì•…í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì œ ëª¨ë¸ APIì€ [ì—¬ê¸°](https://ainize.ai/teachable-ainize/gpt2-train?branch=train/4fcddobl91jcdlqrouqh)ì—ì„œ ì²´í—˜ ê°€ëŠ¥í•˜ê³ , ì‚¬ìš© ë°©ë²•ì„ ì¡°ê¸ˆ ë” ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

Serversë¡œ ëª…ì‹œëœ ì£¼ì†Œì— ëª¨ë¸ì´ ì—…ë¡œë“œ ë˜ì–´ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ ì„œë²„ì— Requestë¥¼ ë³´ëƒ„ìœ¼ë¡œì¨ Responseë¥¼ í†µí•´ ê¸€ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. **INTRO íƒ­**ì— ì•ˆë‚´ëœ `curl` ëª…ë ¹ì–´ë¡œ APIë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆì§€ë§Œ, **APIíƒ­**ì—ì„œ **ë³„ë„ì˜ ì½”ë“œ ì—†ì´** APIë¥¼ í…ŒìŠ¤íŠ¸ í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img width="999" alt="_2021-04-19__11 04 20" src="https://user-images.githubusercontent.com/46207836/115835283-106fca00-a451-11eb-8849-d37dea3128b0.png">

`Try it out!` ì„ í´ë¦­í•˜ê³ , ì§ì ‘ Request bodyë¥¼ ì‘ì„±í•˜ì—¬ ê°„í¸í•˜ê²Œ Responseë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![api](/Users/ieunji/dev/dleunji.github.io/assets/images/post/api.gif)

**POST**

![ìŠ¤í¬ë¦°ìƒ· 2021-04-22 ì˜¤í›„ 4 34 50](https://user-images.githubusercontent.com/46207836/115835936-d652f800-a451-11eb-80b4-2e13bfd7a50c.png)

- `[ëª¨ë¸ ë§í¬]/predictions/gpt-2-en-small-finetune`ì— POST í˜•ì‹ì˜ `Raw JSON Request`ë¥¼ ë³´ë‚´ë©´ ê¸€ì„ ìƒì„±í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  e.g. https://train-qvbpkc5osu32fupvds7b-gpt2-train-teachable-ainize.endpoint.ainize.ai/`predictions/gpt-2-en-small-finetune`

- í—¤ë”ëŠ” `{'Content-Type' : 'application/json; charset=utf-8'}` ì…ë‹ˆë‹¤.

â€‹	ì´ ë•Œ ì£¼ì˜í•  ì ì€ `textê°€ array type`ì…ë‹ˆë‹¤.

âœ°âœ°ë”°ë¼ì„œ `ë°˜ë“œì‹œ textëŠ” Request ì „ì— Tokenizerë¡œ ì¸ì½”ë”©` í•´ì•¼í•©ë‹ˆë‹¤.âœ°âœ°

(í•˜ë‹¨ **3-B** **Backend** ì½”ë“œì— **Tokenizer ì‚¬ìš© ì•ˆë‚´**ê°€ ìˆìŠµë‹ˆë‹¤.)

```json
// e.g.
{
	"text": [464, 26231,2470], //Encoded text
  "length" : 8,
  "num_samples": 2,
}
```

![ìŠ¤í¬ë¦°ìƒ· 2021-04-22 ì˜¤í›„ 4 35 00](https://user-images.githubusercontent.com/46207836/115836087-06020000-a452-11eb-96a0-9adc820e6875.png)

- **POST**

  - `[ëª¨ë¸ ë§í¬]/predictions/gpt-2-en-small-finetune`ì— POST í˜•ì‹ì˜ `Raw JSON Request`ë¥¼ ë³´ë‚´ë©´ ê¸€ì„ ìƒì„±í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    e.g. https://train-qvbpkc5osu32fupvds7b-gpt2-train-teachable-ainize.endpoint.ainize.ai/`predictions/gpt-2-en-small-finetune`

  - í—¤ë”ëŠ” `{'Content-Type' : 'application/json; charset=utf-8'}` ì…ë‹ˆë‹¤.

  [Request Body]

  ì´ ë•Œ ì£¼ì˜í•  ì ì€ `textê°€ array type`ì…ë‹ˆë‹¤.

  âœ°âœ°ë”°ë¼ì„œ `ë°˜ë“œì‹œ textëŠ” Request ì „ì— Tokenizerë¡œ ì¸ì½”ë”©` í•´ì•¼í•©ë‹ˆë‹¤.âœ°âœ°

  (í•˜ë‹¨ **3-B** **Backend** ì½”ë“œì— **Tokenizer ì‚¬ìš© ì•ˆë‚´**ê°€ ìˆìŠµë‹ˆë‹¤.)

  ```json
  // e.g.
  {
  	"text": [464, 26231,2470], //Encoded text
    "length" : 8,
    "num_samples": 2,
  }
  ```

  [Response]

  `Response ë˜í•œ array type`ìœ¼ë¡œ, í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ì„œëŠ” `ë””ì½”ë”©`ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤.

  ```json
  //e.g.
  [
  	[464, 26231, 2470, 114, 55, 4982, 99, 101, 39395, 2222],
  	[464, 26231, 2470, 39948, 57, 26553, 89, 11, 482, 56]
  ]
  ```

- **GET**

  Serverì˜ Health Checkë¥¼ ìœ„í•œ ìš©ë„ì…ë‹ˆë‹¤.

**3. ì„œë¹„ìŠ¤ì— ì ìš©**

ì „ì²´ì ì¸ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

ì €ëŠ” ëª¨ë¸ë¡œ ë‹¨ìˆœíˆ ì¹¸íŠ¸ ì‹ì˜ ë¬¸ì¥ì„ ìƒì„±í•˜ëŠ” ê²ƒë³´ë‹¤ëŠ” ìŠ¤í† ë¦¬ì™€ ë””ìì¸ì„ ë§ë¶™ì˜€ìŠµë‹ˆë‹¤. ë§ˆì¹˜ ì¹¸íŠ¸ê°€ ëŒ€í•„ì‘ê°€(Ghostwriter)ê°€ ë˜ì–´ í•™ìƒë“¤ ëŒ€ì‹  ê¸€ì„ ì¨ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ì›¹í˜ì´ì§€ë¥¼ ì œì‘í•˜ì—¬ ì‚¬ìš©ìê°€ ì—ì„¸ì´ì˜ ìš´ì„ ë„ìš°ë©´ ì¹¸íŠ¸ê°€ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—ì„¸ì´ë¥¼ ë§ˆì € ì‘ì„±í•´ì£¼ëŠ” ì»¨ì…‰ì˜ í˜ì´ì§€ì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ textë¥¼ ì…ë ¥ ë°›ê³ , ê·¸ í›„ í•´ë‹¹ textë¥¼ ì¸ì½”ë”© í›„ `Fetch`ë¥¼ í†µí•´ ëª¨ë¸ APIì˜ POST Requestì— ì „ë‹¬í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í”„ë¡œê·¸ë¨ì„ ì œì‘í•˜ì˜€ìŠµë‹ˆë‹¤.

![TeachableNLPapi 001](https://user-images.githubusercontent.com/46207836/115836353-58dbb780-a452-11eb-91af-fad68a0cb6c7.jpeg)

**A. Frontend**

ì•„ë˜ `id = prefixì¸ inputì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥`ë°›ê³ , `search-btnì´ í´ë¦­ë˜ë©´ submit()í•¨ìˆ˜ë¥¼ í†µí•´ POST request`í•˜ë„ë¡ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.

![TeachableNLPapi2 001](https://user-images.githubusercontent.com/46207836/115836439-71e46880-a452-11eb-977b-cc7ae4284207.jpeg)

â€‹	

```python
import requests
import json
from transformers import AutoTokenizer # For Encoding and Decoding 
autoTokenizer = AutoTokenizer.from_pretrained("gpt2-large")

@app.route('/gpt2', methods=['POST'])
def gpt2():
		# HTMLì—ì„œ ì…ë ¥ë°›ì€ í¼ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    prefix = request.form['context']
		# ì¸ì½”ë”©
    encodedText = autoTokenizer.encode(prefix)
    headers = {'Content-Type' : 'application/json; charset=utf-8'}
    data = {
        'text' : encodedText,
        'length' : 200
				# í•„ìš” ì‹œ num_samples ì„¤ì • ê°€ëŠ¥, ë¯¸ì„¤ì • ì‹œ default value = 1
    }
		# ëª¨ë¸ ì£¼ì†Œ
    url = "<https://train-avgw7n5kbmsb7wrip2a8-gpt2-train-teachable-ainize.endpoint.dev.ainize.ai/predictions/gpt-2-en-small-finetune>"
    # í•´ë‹¹ urlë¡œ POST requestë¥¼ ë³´ë‚¸ í›„, response
		response = requests.post(url, headers = headers, data = json.dumps(data))
    if response.status_code == 200:
        res = response.json()
				# ì •ìƒì ì¸ responseì˜ ê²½ìš°, responseì˜ ê°’ì„ ë””ì½”ë”©
				# skip_special_tokensëŠ” optional, Trueì˜ ê²½ìš° ë””ì½”ë”© ê³¼ì •ì—ì„œ special_tokenì€ ìƒëµ
        text = autoTokenizer.decode(res[0], skip_special_tokens=True)
				# ë””ì½”ë”©ì²˜ë¦¬ í›„ Frontendë¡œ ê°’ ì „ë‹¬
        return jsonify({'text' : text}), 200
    else:
        return jsonify({'fail' : 'eror'}), response.status_code
```

**4. ë§ˆë¬´ë¦¬**

NLPì— ëŒ€í•œ ì§€ì‹ì´ ì „ë¬´í•œ ìƒí™©ì—ì„œ í•´ë‹¹ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì„ì§€ ê±±ì •ì´ ì•ì„°ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë‹¨ìˆœí•œ APIë¥¼ í†µí•´ Teachable NLPë¡œ ë‚˜ë§Œì˜ ëª¨ë¸ì„ í™œìš©í•œ ì„œë¹„ìŠ¤, `Ghostwriter Kant` ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ë§Œì•½ APIë¥¼ ëª¨ë¥´ì‹œë”ë¼ë„ ì œ ì½”ë“œë¥¼ ë³´ì‹ ë‹¤ë©´ ë‹¤ë¥¸ ê°œë°œìë“¤ë„ ê°„ë‹¨í•˜ê²Œ Teachable NLPë¥¼ í™œìš©í•œ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img width="1439" alt="_2021-04-14__4 48 24" src="https://user-images.githubusercontent.com/46207836/115836524-8c1e4680-a452-11eb-8f70-87ef24f52a79.png">

ë˜í•œ ì´ë ‡ê²Œ ì œì‘í•œ Ghostwriter Kantë¥¼ Dockerfileê³¼ í•¨ê»˜ ì—…ë¡œë“œ Githubì— ì—…ë¡œë“œí•œ ë’¤, [Ainize](https://ainize.ai/dleunji/kant?branch=ainize)ì— Githubì— ë ˆí¬ì§€í† ë¦¬ ì£¼ì†Œë¥¼ ì…ë ¥í•˜ê¸°ë§Œ í•˜ë©´ ë³„ë„ì˜ ì„œë²„ ë¹„ìš©ì´ë‚˜ ê´€ë¦¬ ì—†ì´ AI ì„œë¹„ìŠ¤ë¥¼ ë°°í¬í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì œ Ghostwriter Kant ì„œë¹„ìŠ¤ë¥¼ ì²´í—˜í•´ë³´ê³  ì‹¶ì€ ë¶„ë“¤ì€ [ì—¬ê¸°](https://ainize-kant-dleunji.endpoint.ainize.ai/)ë¥¼ í´ë¦­í•´ì£¼ì„¸ìš”.

![_2021-04-16__5 46 14](https://user-images.githubusercontent.com/46207836/115837018-1bc3f500-a453-11eb-9c47-79762e809672.png)

ì €ì™€ ê°™ì€ ë¹„ê¸°ë„ˆë“¤ì—ê²Œ NLP ëª¨ë¸ì„ íŠœë‹í•˜ê³  ì„œë²„ì— í”„ë¡œì íŠ¸ë¥¼ ë°°í¬í•˜ëŠ” ì¼ì€ ì–´ë µê²Œ ëŠê»´ì§ˆ ê²ë‹ˆë‹¤. ê·¸ë¦¬ê³  NLPë¥¼ íŠœë‹í•˜ëŠ” ê³¼ì •ì— í•„ìš”í•œ GPU, ì„œë²„ ë°°í¬ ë¹„ìš©ì€ ë¶€ë‹´ìŠ¤ëŸ½ê¸°ë„ í•©ë‹ˆë‹¤.

í•˜ì§€ë§Œ `Teachable NLP`, `Ainize`ë¥¼ í™œìš©í•œë‹¤ë©´ ê°„ë‹¨í•œ ì½”ë“œ ì‘ì„±ê³¼ í´ë¦­ë§Œìœ¼ë¡œ í”„ë¡œì íŠ¸ë¥¼ ì™„ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ë¶„ë„ ì—¬ëŸ¬ë¶„ë§Œì˜ ì„œë¹„ìŠ¤ë¥¼ [í¬ëŸ¼](https://forum.ainetwork.ai)ì— ê°œë°œí•˜ê³  ìë‘í•´ì£¼ì„¸ìš”! ğŸ˜†



[English ver.]

Teachable NLP is a service that you can fine-tune GPT-2 models with a text file(.txt) without NLP codes.

I used [my model API](https://ainize.ai/teachable-ainize/gpt2-train?branch=train/ssasm20u83txlwa12en6) for my service, '**Ghostwriter Kant**'. My dream has finally come true! As a student majoring in Philosophy, it has been my wish for many years that Kant would write an essay on behalf of [me.To](http://me.To) realize it, I preprocessed the text extracted from â€œThe Critique of Pure Reasonâ€ and trained it with the GPT-2 small/largemodel in Teachable NLP.

As I already explained [the training process](https://www.notion.so/Kant-The-Critique-of-Pure-Reason-a4f5c100e68642f0b07dc4fdf4ac9a3c), I will go into more detail about **using Model API for my own service** in this post.

1. **Check Model ID**

After training, The Teachable NLP screen looks like below.

![_2021-04-16__6 21 07](https://user-images.githubusercontent.com/46207836/115831494-9e958180-a44c-11eb-9135-f5764188f7e2.png)

You can find out the model ID through the url. In my case, URL was like below. 

<img width="621" alt="_2021-04-19__10 21 36" src="https://user-images.githubusercontent.com/46207836/115834651-6b54f180-a450-11eb-8dcc-3262a69f4385.png">

The modle ID is a series of letters in the end of URL, that is `4fcddobl91jcdlqrouqh` .

**2. Model API**

If you click the  `View API` , the `API` guide appears. You can experience my Model API  [here](https://ainize.ai/teachable-ainize/gpt2-train?branch=train/4fcddobl91jcdlqrouqh). Let me show you more detailed guide.

The fine-tuned model is uploaded to the Servers of the url. You can get the generated text through `response` by sending `POST Request`. It is possible to test API not only using `curl` command as it is written in **INTRO Tab**, however, but also using `swagger` in **API Tab** without any codes.

<img width="999" alt="_2021-04-19__11 04 20" src="https://user-images.githubusercontent.com/46207836/115835283-106fca00-a451-11eb-8849-d37dea3128b0.png">

Just click `Try it out!` , and fill out Request body for yourself. Then you can check out Response easily.

![api](/Users/ieunji/dev/dleunji.github.io/assets/images/post/api.gif)

 **POST**

![ìŠ¤í¬ë¦°ìƒ· 2021-04-22 ì˜¤í›„ 4 34 50](https://user-images.githubusercontent.com/46207836/115835936-d652f800-a451-11eb-80b4-2e13bfd7a50c.png)

â€‹	

- Just send  `Raw JSON Request`  in POST method to `[Model url]/predictions/gpt-2-en-small-finetune`

  e.g. https://train-qvbpkc5osu32fupvds7b-gpt2-train-teachable-ainize.endpoint.ainize.ai/`predictions/gpt-2-en-small-finetune`

- The header is  `{'Content-Type' : 'application/json; charset=utf-8'}` .

Be careful to the type of text is `array type` !

âœ°âœ°So you should `encode the text before the Request`.âœ°âœ°

(It is specifically guided to **3-B** **Backend** codes using **Tokenizer**.)

![ìŠ¤í¬ë¦°ìƒ· 2021-04-23 ì˜¤í›„ 4 49 25](https://user-images.githubusercontent.com/46207836/115837766-e7046d80-a453-11eb-81ca-0469b431f83d.png)

- **POST**

  [Request Body]

  - Just send  `Raw JSON Request`  in POST method to `[Model url]/predictions/gpt-2-en-small-finetune`

    e.g. https://train-qvbpkc5osu32fupvds7b-gpt2-train-teachable-ainize.endpoint.ainize.ai/`predictions/gpt-2-en-small-finetune`

  - The header is  `{'Content-Type' : 'application/json; charset=utf-8'}` .

  Be careful to the type of text is `array type` !

  âœ°âœ°So you should `encode the text before the Request`.âœ°âœ°

  (It is specifically guided to **3-B** **Backend** codes using **Tokenizer**.)

  ```json
  // e.g.
  {
  	"text": [464, 26231,2470], //Encoded text
    "length" : 8,
    "num_samples": 2,
  }
  ```

  [Response]

  `Response is also array type`, so you should `decode the array to text`.

  ```json
  //e.g.
  [
  	[464, 26231, 2470, 114, 55, 4982, 99, 101, 39395, 2222],
  	[464, 26231, 2470, 39948, 57, 26553, 89, 11, 482, 56]
  ]
  ```

- **GET**

  It is used for Health Check of server.

**3. Apply to my own service**

It is more understandable with diagram of the API flow. I added story and design to make more interesting service, not just generating the Kantian sentences. As if Kant becomes a ghostwriter and writes an essay in place of students, I made Web page and if user let him know the beginning of the essay, he picks up where we said.

So I made the program **get** some input from users, **encode** the text, **fetch** the generated text using POST Request and finally **decode** the text from response.

![TeachableNLPapi 001](https://user-images.githubusercontent.com/46207836/115836353-58dbb780-a452-11eb-91af-fad68a0cb6c7.jpeg)

**A. Frontend**

Get text through `input of which id is 'prefix'`, and if `search-btn is clicked, POST request occurs through submit()` .

![TeachableNLPapi2 001](https://user-images.githubusercontent.com/46207836/115836439-71e46880-a452-11eb-977b-cc7ae4284207.jpeg)

It is coded using `Promise` of Javascript.

```jsx
function submit(){
	var prefix = document.getElementById("prefix");
	var prefix_value = prefix.value;
	/* If there input box is blank */
	if (prefix_value == ""){
	    alert('Please let me know how to get started!');
	    return;
	}
	var formData = new FormData();
	/* To append the prefix to form data, and make  {"context" : prefix_value}. */
	formData.append("context", prefix_value);
	/* To fetch the form to /gpt2, go through app.py, send Request, and then 
get response from app.py*/
	fetch(
	    "/gpt2", 
	    {
	        method: "POST",
	        body : formData
	    }
	)
	/* The Reponse returned from request is parameter */ 
	/* The request is encoded, and decoded like {'text: "..."} in app.py */
	.then(response => {
	    if(response.status == 200){
	        return response;
	    }
	    else if(response.status == 400){
	        throw Error("Failed1");
	    }
	    else {
	        throw Error("Failed2");
	    }
	})
	.then(response => {
	    res = response.json()
	    return res
	})
	/* To change HTML dynamically */
	.then(response => {
	    var text = response['text'] + "...<br>Now it's your turn!<br><br><br>";
	    document.getElementsByClassName("essay")[0].innerHTML = text;
	})
	/* To handle the errors */
	.catch(e => {
	    var result = document.getElementsByClassName("essay")[0];
	    result.textContent = e;
	})
}
```

**B. Backend**

`Flask`is used for tokenizing .

```python
import requests
import json
from transformers import AutoTokenizer # For Encoding and Decoding 
autoTokenizer = AutoTokenizer.from_pretrained("gpt2-large")

@app.route('/gpt2', methods=['POST'])
def gpt2():
		# Extract text from form data sent from HTML
    prefix = request.form['context']
		# Encoding
    encodedText = autoTokenizer.encode(prefix)
    headers = {'Content-Type' : 'application/json; charset=utf-8'}
    data = {
        'text' : encodedText,
        'length' : 200
				# 'num_samples' key is optional, its default value is 1.
		}
		# The server url
    url = "<https://train-avgw7n5kbmsb7wrip2a8-gpt2-train-teachable-ainize.endpoint.dev.ainize.ai/predictions/gpt-2-en-small-finetune>"
    # To send POST request to url,and get response
		response = requests.post(url, headers = headers, data = json.dumps(data))
    if response.status_code == 200:
        res = response.json()
				# To Decode the value of response if response is valid
				# 'skip_special_tokens' is optional. If it is True, special_token is excepted
        text = autoTokenizer.decode(res[0], skip_special_tokens=True)
				# After decoding, deliver the text to frontend.
        return jsonify({'text' : text}), 200
    else:
        return jsonify({'fail' : 'eror'}), response.status_code
```

**4. Wrap up**

I worried if I could create the `Ghostwriter Kant` in the absence of knowledge of NLP. However, through a simple API of Teachable NLP, I was able to create it with my own model.  Even if you don't know the API, other beginners can easily make service using Teachable NLP refering to my codes.

<img width="1439" alt="_2021-04-14__4 48 24" src="https://user-images.githubusercontent.com/46207836/115836524-8c1e4680-a452-11eb-8f70-87ef24f52a79.png">

Moreover, if you upload the project with `Dockerfile` in Github and just fill out the url of repository of Github in [Ainize](https://ainize.ai/dleunji/kant?branch=ainize), you can serve your own AI service without cost of server.

Anyone who wants to experience my `Ghostwriter Kant` service, please click [here](https://ainize-kant-dleunji.endpoint.ainize.ai/)!

![_2021-04-16__5 46 14](https://user-images.githubusercontent.com/46207836/115837018-1bc3f500-a453-11eb-9c47-79762e809672.png)

It may be difficult for beginners to fine-tune the model and serve the project. Also the GPU needed to fine-tuning, and the cost of server is more intolerably burdensome.

But `Teachable NLP`, `Ainize` solve the problems. You just write some codes and clicks, you can complete your own project! How about boasting of your service in the [forum](https://forum.ainetwork.ai)! ğŸ˜†



